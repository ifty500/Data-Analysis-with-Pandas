{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "A huge part of data science involves acquiring raw data and getting it into a form ready for analysis. Some have estimated that data scientists spend 80% of their time cleaning and manipulating data, and only 20% of their time actually analyzing it or building models from it.\n",
    "\n",
    "When we receive raw data, we have to do a number of things before we’re ready to analyze it, possibly including:\n",
    "\n",
    "* diagnosing the “tidiness” of the data — how much data cleaning we will have to do\n",
    "* reshaping the data — getting right rows and columns for effective analysis\n",
    "* combining multiple files\n",
    "* changing the types of values — how we fix a column where numerical values are stored as strings, for example\n",
    "* dropping or filling missing values - how we deal with data that is incomplete or missing\n",
    "* manipulating strings to represent the data better\n",
    "\n",
    "We will go through the techniques data scientists use to accomplish these goals by looking at some “unclean” datasets and trying to get them into a good, clean state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Unnamed: 0            full_name gender_age Fractions Probability  \\\n",
      "0            0       Barrett Feragh        M14       76%         72%   \n",
      "1            1      Llewellyn Keech        M14       83%         87%   \n",
      "2            2    Delilah Sowthcote        F16       90%         79%   \n",
      "3            3         Terrell Geri        M15       80%         86%   \n",
      "4            4       Gram Hallewell        M14       67%         78%   \n",
      "5            5       Stephana Boots        F18       74%         85%   \n",
      "6            6    Adrianne Bamfield        F14       91%         75%   \n",
      "7            7       Glynnis Eglise        F18       84%         74%   \n",
      "8            8        Ronnica Cough        F15       77%         84%   \n",
      "9            9      Kenyon Brisland        M18       68%         91%   \n",
      "10          10    Sherman Holdforth        M18       79%         69%   \n",
      "11          11          Zeke Marson        M14       73%         69%   \n",
      "12          12        Alexis Selbie        F17       61%         84%   \n",
      "13          13     Harcourt Bratton        M14       73%         76%   \n",
      "14          14      Cully Sandbatch        M16       65%         88%   \n",
      "15          15       Stephan Dufore        M14       84%         77%   \n",
      "16          16      Allayne Lettley        M15       69%         81%   \n",
      "17          17        Jamima Loweth        F16       74%         90%   \n",
      "18          18     Basil Choulerton        M18       63%         80%   \n",
      "19          19       Carmine Dewitt        M17       79%         83%   \n",
      "20          20      Gretna Ashborne        F16       84%         78%   \n",
      "21          21    L;urette Preskett        F15       73%         85%   \n",
      "22          22    Thorvald Slograve        M18       84%         88%   \n",
      "23          23    Averil Petheridge        F16       78%         88%   \n",
      "24          24         Reece Haslam        M15       71%         67%   \n",
      "25          25       Rudolfo Welsby        M18       80%         75%   \n",
      "26          26          Page Vooght        F15       77%         77%   \n",
      "27          27         Charo Feragh        F18       79%         79%   \n",
      "28          28      Carmine Henriet        M18       78%         86%   \n",
      "29          29        Ado Hawlgarth        M16       63%         82%   \n",
      "..         ...                  ...        ...       ...         ...   \n",
      "70          70    Sergeant Witherow        M15       69%         89%   \n",
      "71          71     Sharleen Broadey        F15       80%         81%   \n",
      "72          72     Deeann Duckworth        F16       71%         83%   \n",
      "73          73        Gerry Rangall        F15       74%         74%   \n",
      "74          74       Nissy Ogglebie        F14       77%         82%   \n",
      "75          75    Colver de Copeman        M18       85%         86%   \n",
      "76          76          Pammi Swaby        F14       56%         75%   \n",
      "77          77           Niels Lean        M17       77%         74%   \n",
      "78          78             Ali Ling        F17       71%         78%   \n",
      "79          79            Ode Evamy        M15       88%         80%   \n",
      "80          80       Claudetta Tyne        F17       79%         95%   \n",
      "81          81     Jennilee Megroff        F14       85%         79%   \n",
      "82          82       Sauveur Grouen        M15       62%         87%   \n",
      "83          83      Price Pallister        M14       58%         76%   \n",
      "84          84    Corabelle Zaniolo        F15       67%         76%   \n",
      "85          85            Ker Tween        M18       87%         84%   \n",
      "86          86      Norton Coleford        M15       80%         74%   \n",
      "87          87   Bonny Bartoszewicz        F16       90%         89%   \n",
      "88          88      Winonah Le-Good        F18       84%         84%   \n",
      "89          89   Lodovico Backhurst        M14       79%         88%   \n",
      "90          90          Bart Parres        M17       87%         77%   \n",
      "91          91           Jami Milam        F15       63%         76%   \n",
      "92          92  Merlina Aleshintsev        F16       50%         86%   \n",
      "93          93          Elysia Rime        F14       73%         89%   \n",
      "94          94      Lovell Coolican        M18       70%         84%   \n",
      "95          95        Halley Clunie        F14       73%         82%   \n",
      "96          96       Gale Mullender        F17       72%         81%   \n",
      "97          97           Ryun Denne        M17       74%         78%   \n",
      "98          98     Cazzie Potapczuk        M14       71%         78%   \n",
      "99          99        Verina Pasque        F18       48%         77%   \n",
      "\n",
      "         grade  \n",
      "0    9th grade  \n",
      "1   12th grade  \n",
      "2   10th grade  \n",
      "3   11th grade  \n",
      "4   10th grade  \n",
      "5    9th grade  \n",
      "6   11th grade  \n",
      "7   10th grade  \n",
      "8    9th grade  \n",
      "9   12th grade  \n",
      "10  10th grade  \n",
      "11  10th grade  \n",
      "12  12th grade  \n",
      "13  10th grade  \n",
      "14   9th grade  \n",
      "15  10th grade  \n",
      "16  10th grade  \n",
      "17  12th grade  \n",
      "18  12th grade  \n",
      "19   9th grade  \n",
      "20  11th grade  \n",
      "21  11th grade  \n",
      "22  11th grade  \n",
      "23  10th grade  \n",
      "24  11th grade  \n",
      "25   9th grade  \n",
      "26  12th grade  \n",
      "27   9th grade  \n",
      "28   9th grade  \n",
      "29  10th grade  \n",
      "..         ...  \n",
      "70  11th grade  \n",
      "71  10th grade  \n",
      "72  10th grade  \n",
      "73  12th grade  \n",
      "74  12th grade  \n",
      "75  10th grade  \n",
      "76  11th grade  \n",
      "77   9th grade  \n",
      "78  12th grade  \n",
      "79  12th grade  \n",
      "80  12th grade  \n",
      "81  12th grade  \n",
      "82   9th grade  \n",
      "83  12th grade  \n",
      "84  12th grade  \n",
      "85  12th grade  \n",
      "86  11th grade  \n",
      "87  12th grade  \n",
      "88   9th grade  \n",
      "89  12th grade  \n",
      "90   9th grade  \n",
      "91  11th grade  \n",
      "92  11th grade  \n",
      "93  11th grade  \n",
      "94  11th grade  \n",
      "95  12th grade  \n",
      "96  12th grade  \n",
      "97  11th grade  \n",
      "98  10th grade  \n",
      "99  10th grade  \n",
      "\n",
      "[100 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "students0 = pd.read_csv(\"data/file0.csv\")\n",
    "students1 = pd.read_csv(\"data/file1.csv\")\n",
    "\n",
    "print(students0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diagnose the Data\n",
    "We often describe data that is easy to analyze and visualize as “tidy data”. What does it mean to have tidy data?\n",
    "\n",
    "For data to be tidy, it must have:\n",
    "\n",
    "* Each variable as a separate column\n",
    "* Each row as a separate observation\n",
    "\n",
    "For example, we would want to reshape a table like:\n",
    "\n",
    "Account\tCheckings\tSavings\n",
    "“12456543”\t8500\t8900\n",
    "“12283942”\t6410\t8020\n",
    "“12839485”\t78000\t92000\n",
    "\n",
    "Into a table that looks more like:\n",
    "\n",
    "Account\tAccount Type\tAmount\n",
    "“12456543”\t“Checking”\t8500\n",
    "“12456543”\t“Savings”\t8900\n",
    "“12283942”\t“Checking”\t6410\n",
    "“12283942”\t“Savings”\t8020\n",
    "“12839485”\t“Checking”\t78000\n",
    "“12839485”\t“Savings”\t920000\n",
    "\n",
    "The first step of diagnosing whether or not a dataset is tidy is using pandas functions to explore and probe the dataset.\n",
    "\n",
    "You’ve seen most of the functions we often use to diagnose a dataset for cleaning. Some of the most useful ones are:\n",
    "\n",
    "* .head() — display the first 5 rows of the table\n",
    "* .info() — display a summary of the table\n",
    "* .describe() — display the summary statistics of the table\n",
    "* .columns — display the column names of the table\n",
    "* .value_counts() — display the distinct values for a column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "1.\n",
    "We have provided two DataFrames, df1 and df2.\n",
    "\n",
    "Inspect both of these DataFrames using the functions listed above.\n",
    "\n",
    "Start by printing the .head() of both df1 and df2.\n",
    "\n",
    "\n",
    "2.\n",
    "Explore the DataFrames using the other functions listed.\n",
    "\n",
    "Which DataFrame is “clean”, and ready for analysis? Create a variable named clean and set it equal to 1 for df1 and 2 for df2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Grocery Item  Cake Recipe  Pancake Recipe  Cookie Recipe\n",
      "0         Eggs            2               3              1\n",
      "1         Milk            1               2              1\n",
      "2        Flour            2               1              2\n",
      "  Grocery Item          Recipe  Number\n",
      "0         Eggs     Cake Recipe       2\n",
      "1         Milk     Cake Recipe       1\n",
      "2        Flour     Cake Recipe       2\n",
      "3         Eggs  Pancake Recipe       3\n",
      "4         Milk  Pancake Recipe       2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv(\"data/df1.csv\")\n",
    "df2 = pd.read_csv(\"data/df2.csv\")\n",
    "\n",
    "print(df1.head())\n",
    "print(df2.head())\n",
    "\n",
    "clean = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with Multiple Files\n",
    "Often, you have the same data separated out into multiple files.\n",
    "\n",
    "Let’s say that we have a ton of files following the filename structure: 'file1.csv', 'file2.csv', 'file3.csv', and so on. The power of pandas is mainly in being able to manipulate large amounts of structured data, so we want to be able to get all of the relevant information into one table so that we can analyze the aggregate data.\n",
    "\n",
    "We can combine the use of glob, a Python library for working with files, with pandas to organize this data better. glob can open multiple files by using regex matching to get the filenames:\n",
    "\n",
    "    import glob\n",
    "\n",
    "    files = glob.glob(\"file*.csv\")\n",
    "\n",
    "    df_list = []\n",
    "    for filename in files:\n",
    "      data = pd.read_csv(filename)\n",
    "      df_list.append(data)\n",
    "\n",
    "    df = pd.concat(df_list)\n",
    "\n",
    "    print(files)\n",
    "    \n",
    "This code goes through any file that starts with 'file' and has an extension of .csv. It opens each file, reads the data into a DataFrame, and then concatenates all of those DataFrames together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "1.\n",
    "We have 10 different files containing 100 students each. These files follow the naming structure:\n",
    "\n",
    "exams0.csv\n",
    "exams1.csv\n",
    "… up to exams9.csv\n",
    "We are going to import each file using pandas, and combine all of the entries into one DataFrame.\n",
    "\n",
    "First, create a variable called student_files and set it equal to the glob() of all of the csv files we want to import.\n",
    "\n",
    "Checkpoint 2 Passed\n",
    "\n",
    "Stuck? Get a hint\n",
    "2.\n",
    "Create an empty list called df_list that will store all of the DataFrames we make from the files exams0.csv through exams9.csv.\n",
    "\n",
    "Checkpoint 3 Passed\n",
    "3.\n",
    "Loop through the filenames in student_files, and create a DataFrame from each file. Append this DataFrame to df_list.\n",
    "\n",
    "Checkpoint 4 Passed\n",
    "\n",
    "Stuck? Get a hint\n",
    "4.\n",
    "Concatenate all of the DataFrames in df_list into one DataFrame called students.\n",
    "\n",
    "Checkpoint 5 Passed\n",
    "\n",
    "Stuck? Get a hint\n",
    "5.\n",
    "Print students and the length of students. Did we get all of them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id        full_name gender_age fractions probability       grade\n",
      "0   0   Barrett Feragh        M14       76%         72%   9th grade\n",
      "1   1  Llewellyn Keech        M14       83%         NaN  12th grade\n",
      "2   2  Llewellyn Keech        M14       83%         NaN  12th grade\n",
      "3   3     Terrell Geri        M15       80%         86%  11th grade\n",
      "4   4   Gram Hallewell        M14       67%         78%  10th grade\n",
      "700\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "student_files = glob.glob(\"data/exam*.csv\")\n",
    "\n",
    "df_list = []\n",
    "\n",
    "for filename in student_files:\n",
    "  df_list.append(pd.read_csv(filename))\n",
    "  \n",
    "students = pd.concat(df_list)\n",
    "\n",
    "print(students.head())\n",
    "print(len(students))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reshaping your Data\n",
    "Since we want\n",
    "\n",
    "* Each variable as a separate column\n",
    "* Each row as a separate observation\n",
    "\n",
    "We would want to reshape a table like:\n",
    "\n",
    "Account\tChecking\tSavings\n",
    "“12456543”\t8500\t8900\n",
    "“12283942”\t6410\t8020\n",
    "“12839485”\t78000\t92000\n",
    "\n",
    "Into a table that looks more like:\n",
    "Account\tAccount Type\tAmount\n",
    "“12456543”\t“Checking”\t8500\n",
    "“12456543”\t“Savings”\t8900\n",
    "“12283942”\t“Checking”\t6410\n",
    "“12283942”\t“Savings”\t8020\n",
    "“12839485”\t“Checking”\t78000\n",
    "“12839485”\t“Savings”\t920000\n",
    "\n",
    "We can use pd.melt() to do this transformation. .melt() takes in a DataFrame, and the columns to unpack:\n",
    "\n",
    "    pd.melt(frame=df, id_vars='name', value_vars=['Checking','Savings'], value_name=\"Amount\", var_name=\"Account Type\")\n",
    "    \n",
    "The parameters you provide are:\n",
    "\n",
    "* frame: the DataFrame you want to melt\n",
    "* id_vars: the column(s) of the old DataFrame to preserve\n",
    "* value_vars: the column(s) of the old DataFrame that you want to turn into variables\n",
    "* value_name: what to call the column of the new DataFrame that stores the values\n",
    "* var_name: what to call the column of the new DataFrame that stores the variables\n",
    "\n",
    "The default names may work in certain situations, but it’s best to always have data that is self-explanatory. Thus, we often use .columns() to rename the columns after melting:\n",
    "\n",
    "    df.columns([\"Account\", \"Account Type\", \"Amount\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "1.\n",
    "Print out the columns of students.\n",
    "\n",
    "Checkpoint 2 Passed\n",
    "2.\n",
    "There is a column for the scores on the fractions exam, and a column for the scores on the probabilities exam.\n",
    "\n",
    "We want to make each row an observation, so we want to transform this table to look like:\n",
    "\n",
    "full_name\texam\tscore\tgender_age\tgrade\n",
    "“First Student”\t“Fractions”\tscore%\t…\t…\n",
    "“First Student”\t“Probabilities”\tscore%\t…\t…\n",
    "“Second Student”\t“Fractions”\tscore%\t…\t…\n",
    "“Second Student”\t“Probabilities”\tscore%\t…\t…\n",
    "…\t…\t…\t\t\n",
    "Use pd.melt() to create a new table (still called students) that follows this structure.\n",
    "\n",
    "Checkpoint 3 Passed\n",
    "\n",
    "Stuck? Get a hint\n",
    "3.\n",
    "Print the .head() and the .columns of students.\n",
    "\n",
    "Also, print out the .value_counts() of the column exam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'full_name', 'gender_age', 'fractions', 'probability',\n",
      "       'grade'],\n",
      "      dtype='object')\n",
      "           full_name gender_age       grade       exam score\n",
      "0     Moses Kirckman        M14  11th grade  fractions   69%\n",
      "1    Timofei Strowan        M18  11th grade  fractions   63%\n",
      "2       Silvain Poll        M18   9th grade  fractions   69%\n",
      "3     Lezley Pinxton        M18  11th grade  fractions   NaN\n",
      "4  Bernadene Saunper        F17  11th grade  fractions   72%\n",
      "Index(['full_name', 'gender_age', 'grade', 'exam', 'score'], dtype='object')\n",
      "fractions      1000\n",
      "probability    1000\n",
      "Name: exam, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "students = pd.read_csv('data/students.csv')\n",
    "print(students.columns)\n",
    "students = pd.melt(frame=students, id_vars=['full_name','gender_age','grade'], value_vars=['fractions', 'probability'], value_name='score', var_name='exam')\n",
    "\n",
    "print(students.head())\n",
    "print(students.columns)\n",
    "print(students.exam.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with Duplicates\n",
    "Often we see duplicated rows of data in the DataFrames we are working with. This could happen due to errors in data collection or in saving and loading the data.\n",
    "\n",
    "To check for duplicates, we can use the pandas function .duplicated(), which will return a Series telling us which rows are duplicate rows.\n",
    "\n",
    "Let’s say we have a DataFrame fruits that represents this table:\n",
    "\n",
    "|item|\tprice|\tcalories|\n",
    "|---|---|---|\n",
    "|“banana”|\t“1”|\t105|\n",
    "|“apple”|\t“0.75”| 95|\n",
    "|“apple”|\t“0.75”\t|95|\n",
    "|“peach”|\t“3”\t|55|\n",
    "|“peach”|\t“4”\t|55|\n",
    "|“clementine”|“2.5”|35|\n",
    "\n",
    "If we call fruits.duplicated(), we would get the following table:\n",
    "\n",
    "id\tvalue\n",
    "0\tFalse\n",
    "1\tFalse\n",
    "2\tTrue\n",
    "3\tFalse\n",
    "4\tFalse\n",
    "5\tFalse\n",
    "\n",
    "We can see that row 2, which represents an \"apple\" with price \"$0.75\" and 95 calories, is a duplicate row. Every value in this row is the same as in another row.\n",
    "\n",
    "We can use the pandas .drop_duplicates() function to remove all rows that are duplicates of another row.\n",
    "\n",
    "If we call fruits.drop_duplicates(), we would get the table:\n",
    "\n",
    "|item|\tprice|\tcalories|\n",
    "|---|---|---|\n",
    "|“banana”|\t“1”|\t105|\n",
    "|“apple”|\t“0.75”| 95|\n",
    "|“peach”|\t“3”\t|55|\n",
    "|“peach”|\t“4”\t|55|\n",
    "|“clementine”|“2.5”|35|\n",
    "\n",
    "The \"apple\" row was deleted because it was exactly the same as another row. But the two \"peach\" rows remain because there is a difference in the price column.\n",
    "\n",
    "If we wanted to remove every row with a duplicate value in the item column, we could specify a subset:\n",
    "\n",
    "fruits = fruits.drop_duplicates(subset=['item'])\n",
    "By default, this keeps the first occurrence of the duplicate:\n",
    "\n",
    "|item|\tprice|\tcalories|\n",
    "|---|---|---|\n",
    "|“banana”|\t“1”|\t105|\n",
    "|“apple”|\t“0.75”| 95|\n",
    "|“peach”|\t“3”\t|55|\n",
    "|“clementine”|“2.5”|35|\n",
    "\n",
    "Make sure that the columns you drop duplicates from are specifically the ones where duplicates don’t belong. You wouldn’t want to drop duplicates with the price column as a subset, for example, because it’s okay if multiple items cost the same amount!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "students = pd.read_csv(\"data/students.csv\")\n",
    "students = students[['full_name', 'gender_age','fractions','probability','grade']]\n",
    "students = pd.melt(frame=students, id_vars=['full_name','gender_age','grade'], value_vars=['fractions', 'probability'], value_name='score', var_name='exam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    False\n",
      "1    False\n",
      "2    False\n",
      "3    False\n",
      "4    False\n",
      "dtype: bool\n",
      "False    1976\n",
      "True       24\n",
      "dtype: int64\n",
      "0    False\n",
      "1    False\n",
      "2    False\n",
      "3    False\n",
      "4    False\n",
      "dtype: bool\n",
      "False    1976\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "duplicates = students.duplicated()\n",
    "print(duplicates.head())\n",
    "print(duplicates.value_counts())\n",
    "students = students.drop_duplicates()\n",
    "duplicates = students.duplicated()\n",
    "print(duplicates.head())\n",
    "print(duplicates.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting by Index\n",
    "In trying to get clean data, we want to make sure each column represents one type of measurement. Often, multiple measurements are recorded in the same column, and we want to separate these out so that we can do individual analysis on each variable.\n",
    "\n",
    "Let’s say we have a column “birthday” with data formatted in MMDDYYYY format. In other words, “11011993” represents a birthday of November 1, 1993. We want to split this data into day, month, and year so that we can use these columns as separate features.\n",
    "\n",
    "In this case, we know the exact structure of these strings. The first two characters will always correspond to the month, the second two to the day, and the rest of the string will always correspond to year. We can easily break the data into three separate columns by splitting the strings using .str:\n",
    "\n",
    "    # Create the 'month' column\n",
    "    df['month'] = df.birthday.str[0:2]\n",
    "\n",
    "    # Create the 'day' column\n",
    "    df['day'] = df.birthday.str[2:4]\n",
    "\n",
    "    # Create the 'year' column\n",
    "    df['year'] = df.birthday.str[4:]\n",
    "    \n",
    "The first command takes the first two characters of each value in the birthday column and puts it into a month column. The second command takes the second two characters of each value in the birthday column and puts it into a day column. The third command takes the rest of each value in the birthday column and puts it into a year column.\n",
    "\n",
    "This would transform a table like:\n",
    "\n",
    "id\tbirthday\n",
    "1011\t“12241989”\n",
    "1112\t“10311966”\n",
    "1113\t“01052011”\n",
    "\n",
    "into a table like:\n",
    "\n",
    "id\tbirthday\tmonth\tday\tyear\n",
    "1011\t“12241989”\t“12”\t“24”\t“1989”\n",
    "1112\t“10311966”\t“10”\t“31”\t“1966”\n",
    "1113\t“01052011”\t“01”\t“05”\t“2011”\n",
    "\n",
    "We will practice changing string columns into numerical columns (like converting \"10\" to 10) in a future exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "1.\n",
    "Print out the columns of the students DataFrame.\n",
    "\n",
    "Checkpoint 2 Passed\n",
    "2.\n",
    "The column gender_age sounds like it contains both gender and age!\n",
    "\n",
    "Print out the .head() of the column to see what kind of data it contains.\n",
    "\n",
    "Checkpoint 3 Passed\n",
    "\n",
    "Stuck? Get a hint\n",
    "3.\n",
    "It looks like the first character of the values in gender_age contains the gender, while the rest of the string contains the age. Let’s separate out the gender data into a new column called gender.\n",
    "\n",
    "Checkpoint 4 Passed\n",
    "\n",
    "Stuck? Get a hint\n",
    "4.\n",
    "Now, separate out the age data into a new column called age.\n",
    "\n",
    "Checkpoint 5 Passed\n",
    "\n",
    "Stuck? Get a hint\n",
    "5.\n",
    "Good job! Let’s print the .head() of students to see how the DataFrame looks after our creation of new columns.\n",
    "\n",
    "Checkpoint 6 Passed\n",
    "6.\n",
    "Now, we don’t need that gender_age column anymore.\n",
    "\n",
    "Let’s set the students DataFrame to be the students DataFrame with all columns except gender_age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['full_name', 'gender_age', 'grade', 'exam', 'score'], dtype='object')\n",
      "0    M14\n",
      "1    M18\n",
      "2    M18\n",
      "3    M18\n",
      "4    F17\n",
      "Name: gender_age, dtype: object\n",
      "           full_name gender_age       grade       exam score gender age\n",
      "0     Moses Kirckman        M14  11th grade  fractions   69%      M  14\n",
      "1    Timofei Strowan        M18  11th grade  fractions   63%      M  18\n",
      "2       Silvain Poll        M18   9th grade  fractions   69%      M  18\n",
      "3     Lezley Pinxton        M18  11th grade  fractions   NaN      M  18\n",
      "4  Bernadene Saunper        F17  11th grade  fractions   72%      F  17\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "print(students.columns)\n",
    "print(students.gender_age.head())\n",
    "\n",
    "students['gender'] = students.gender_age.str[0]\n",
    "students['age'] = students.gender_age.str[1:]\n",
    "print(students.head())\n",
    "students = students[['full_name','exam','grade','score','gender','age']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting by Character\n",
    "Let’s say we have a column called “type” with data entries in the format \"admin_US\" or \"user_Kenya\". Just like we saw before, this column actually contains two types of data. One seems to be the user type (with values like “admin” or “user”) and one seems to be the country this user is in (with values like “US” or “Kenya”).\n",
    "\n",
    "We can no longer just split along the first 4 characters because admin and user are of different lengths. Instead, we know that we want to split along the \"_\". Using that, we can split this column into two separate, cleaner columns:\n",
    "\n",
    "    # Create the 'str_split' column\n",
    "    df['str_split'] = df.type.str.split('_')\n",
    "\n",
    "    # Create the 'usertype' column\n",
    "    df['usertype'] = df.str_split.str.get(0)\n",
    "\n",
    "    # Create the 'country' column\n",
    "    df['country'] = df.str_split.str.get(1)\n",
    "    \n",
    "This would transform a table like:\n",
    "\n",
    "|id|\ttype|\n",
    "|---|---|\n",
    "|011|\t“user_Kenya”|\n",
    "|1112|\t“admin_US”|\n",
    "|1113|\t“moderator_UK”|\n",
    "\n",
    "into a table like:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "1.\n",
    "The students’ names are stored in a column called full_name.\n",
    "\n",
    "We want to separate this data out into two new columns, first_name and last_name.\n",
    "\n",
    "First, let’s create a Series object called name_split that splits the full_name by the \" \" character.\n",
    "\n",
    "Checkpoint 2 Passed\n",
    "2.\n",
    "Now, let’s create a column called first_name that takes the first item in name_split.\n",
    "\n",
    "Checkpoint 3 Passed\n",
    "3.\n",
    "Finally, let’s create a column called last_name that takes the second item in name_split.\n",
    "\n",
    "Checkpoint 4 Passed\n",
    "4.\n",
    "Print out the .head() of students to see how the DataFrame has changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           full_name       exam       grade score gender age first_name  \\\n",
      "0     Moses Kirckman  fractions  11th grade   69%      M  14      Moses   \n",
      "1    Timofei Strowan  fractions  11th grade   63%      M  18    Timofei   \n",
      "2       Silvain Poll  fractions   9th grade   69%      M  18    Silvain   \n",
      "3     Lezley Pinxton  fractions  11th grade   NaN      M  18     Lezley   \n",
      "4  Bernadene Saunper  fractions  11th grade   72%      F  17  Bernadene   \n",
      "\n",
      "  last_name  \n",
      "0  Kirckman  \n",
      "1   Strowan  \n",
      "2      Poll  \n",
      "3   Pinxton  \n",
      "4   Saunper  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "name_split = students['full_name'].str.split(\" \")\n",
    "students['first_name'] = name_split.str.get(0)\n",
    "students['last_name'] = name_split.str.get(1)\n",
    "\n",
    "print(students.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looking at Types\n",
    "Each column of a DataFrame can hold items of the same data type or dtype. The dtypes that pandas uses are: float, int, bool, datetime, timedelta, category and object. Often, we want to convert between types so that we can do better analysis. If a numerical category like \"num_users\" is stored as a Series of objects instead of ints, for example, it makes it more difficult to do something like make a line graph of users over time.\n",
    "\n",
    "To see the types of each column of a DataFrame, we can use:\n",
    "\n",
    "print(df.dtypes)\n",
    "For a DataFrame like this:\n",
    "\n",
    "\n",
    "\n",
    "|item|\tprice|\tcalories|\n",
    "|---|---|---|\n",
    "|“banana”|\t“1”|\t105|\n",
    "|“apple”|\t“0.75”| 95|\n",
    "|“peach”|\t“3”\t|55|\n",
    "|“clementine”|“2.5”|35|\n",
    "\n",
    "the .dtypes attribute would be:\n",
    "\n",
    "    item        object\n",
    "    price       object\n",
    "    calories     int64\n",
    "    dtype: object\n",
    "    \n",
    "We can see that the dtype of the dtypes attribute itself is an object! It is a Series object, which you have already worked with. Series objects compose all DataFrames.\n",
    "\n",
    "We can see that the price column is made up of objects, which will probably make our analysis of price more difficult. We’ll look at how to convert columns into numeric values in the next few exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "1.\n",
    "Let’s inspect the dtypes in the students table.\n",
    "\n",
    "Print out the .dtypes attribute.\n",
    "\n",
    "Checkpoint 2 Passed\n",
    "2.\n",
    "If we wanted to make a scatterplot of age vs average exam score, would we be able to do it with this type of data?\n",
    "\n",
    "Try to print out the mean of the score column of students."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full_name     object\n",
      "exam          object\n",
      "grade         object\n",
      "score         object\n",
      "gender        object\n",
      "age           object\n",
      "first_name    object\n",
      "last_name     object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "print(students.dtypes)\n",
    "\n",
    "#print(students.score.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# String Parsing\n",
    "Sometimes we need to modify strings in our DataFrames to help us transform them into more meaningful metrics. For example, in our fruits table from before:\n",
    "\n",
    "|item|\tprice|\tcalories|\n",
    "|---|---|---|\n",
    "|“banana”|\t“1”|\t105|\n",
    "|“apple”|\t“0.75”| 95|\n",
    "|“peach”|\t“3”\t|55|\n",
    "|“peach”|\t“4”\t|55|\n",
    "|“clementine”|“2.5”|35|\n",
    "\n",
    "We can see that the 'price' column is actually composed of strings representing dollar amounts. This column could be much better represented in floats, so that we could take the mean, calculate other aggregate statistics, or compare different fruits to one another in terms of price.\n",
    "\n",
    "First, we can use what we know of regex to get rid of all of the dollar signs:\n",
    "\n",
    "    fruit.price = fruit['price'].replace('[\\$,]', '', regex=True)\n",
    "\n",
    "Then, we can use the pandas function .to_numeric() to convert strings containing numerical values to integers or floats:\n",
    "\n",
    "    fruit.price = pd.to_numeric(fruit.price)\n",
    "\n",
    "Now, we have a DataFrame that looks like:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "1.\n",
    "We saw in the last exercise that finding the mean of the score column is hard to do when the data is stored as Objects and not numbers.\n",
    "\n",
    "Use regex to take out the % signs in the score column.\n",
    "\n",
    "Checkpoint 2 Passed\n",
    "\n",
    "Stuck? Get a hint\n",
    "2.\n",
    "Convert the score column to a numerical type using the pd.to_numeric() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69.0\n",
      "77.69657422512235\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "students.score = students['score'].replace('[\\%,]', '', regex=True)\n",
    "students.score = pd.to_numeric(students['score'])\n",
    "\n",
    "print(students.score[0])\n",
    "print(students.score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More String Parsing\n",
    "Sometimes we want to do analysis on numbers that are hidden within string values. We can use regex to extract this numerical data from the strings they are trapped in. Suppose we had this DataFrame df representing a workout regimen:\n",
    "\n",
    "|date|\texerciseDescription|\n",
    "|---|---|\n",
    "|10/18/2018|“lunges - 30 reps”|\n",
    "|10/18/2018\t|“squats - 20 reps”|\n",
    "|10/18/2018\t|“deadlifts - 25 reps”|\n",
    "|10/18/2018\t|“jumping jacks - 30 reps”|\n",
    "|10/19/2018\t|“lunges - 40 reps”|\n",
    "|10/19/2018\t|“chest flyes - 15 reps”|\n",
    "…\t…\n",
    "\n",
    "It would be helpful to separate out data like \"30 lunges\" into 2 columns with the number of reps, \"30\", and the type of exercise, \"lunges\". Then, we could compare the increase in the number of lunges done over time, for example.\n",
    "\n",
    "To extract the numbers from the string we can use pandas’ .str.split() function:\n",
    "\n",
    "    split_df = df['exerciseDescription'].str.split('(\\d+)', expand=True)\n",
    "\n",
    "which would result in this DataFrame split_df:\n",
    "\n",
    "* *\t0\t1\t2\n",
    "0\t“lunges - “\t“30”\t“reps”\n",
    "1\t“squats - “\t“20”\t“reps”\n",
    "2\t“deadlifts - “\t“25”\t“reps”\n",
    "3\t“jumping jacks - “\t“30”\t“reps”\n",
    "4\t“lunges - “\t“40”\t“reps”\n",
    "5\t“chest flyes - “\t“15”\t“reps”\n",
    "\n",
    "Then, we can assign columns from this DataFrame to the original df:\n",
    "\n",
    "    df.reps = pd.to_numeric(split_df[1])\n",
    "    df.exercise = split_df[2].replace('[\\- ]', '', regex=True)\n",
    "    \n",
    "Now, our df looks like this:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "1.\n",
    "Print out the first five rows of the grade column.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "2.\n",
    "Each value in grade looks like “9th grade”, “10th grade”, “11th grade”, or “12th grade”.\n",
    "\n",
    "We want to pare that down to just having the numerical grade. Maybe we want to do linear regression on this data, which would require numerical inputs.\n",
    "\n",
    "Use regex to extract the number from each string in grade and store those values back into the grade column.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "3.\n",
    "Print the dtypes of the students table.\n",
    "\n",
    "\n",
    "4.\n",
    "Convert the grade column to be numerical values instead of objects.\n",
    "\n",
    "\n",
    "5.\n",
    "Calculate the mean of grade, store it in a variable called avg_grade, and then print it out!\n",
    "\n",
    "We could not have done this with strings like “9th grade” or “10th grade”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    11th grade\n",
      "1    11th grade\n",
      "2     9th grade\n",
      "3    11th grade\n",
      "4    11th grade\n",
      "Name: grade, dtype: object\n",
      "full_name      object\n",
      "exam           object\n",
      "grade          object\n",
      "score         float64\n",
      "gender         object\n",
      "age            object\n",
      "first_name     object\n",
      "last_name      object\n",
      "dtype: object\n",
      "10.620445344129555\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "print(students.grade.head())\n",
    "\n",
    "students.grade = students.grade.str.split('(\\d+)', expand=True)[1]\n",
    "\n",
    "print(students.dtypes)\n",
    "\n",
    "students.grade = pd.to_numeric(students.grade)\n",
    "avg_grade = students.grade.mean()\n",
    "\n",
    "print(avg_grade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing Values\n",
    "We often have data with missing elements, as a result of a problem with the data collection process or errors in the way the data was stored. The missing elements normally show up as NaN (or Not a Number) values:\n",
    "\n",
    "|day|\tbill|\ttip|\tnum_guests|\n",
    "|---|---|---|---|\n",
    "|“Mon”\t|10.1|\t1|\t1|\n",
    "|“Mon”\t|20.75|\t5.5|\t2|\n",
    "|“Tue”\t|19.95|\t5.5\t|NaN|\n",
    "|“Wed”\t|44.10|\t15\t|3|\n",
    "|“Wed”\t|NaN\t|1\t|1|\n",
    "\n",
    "The num_guests value for the 3rd row is missing, and the bill value for the 5th row is missing. Some calculations we do will just skip the NaN values, but some calculations or visualizations we try to perform will break when a NaN is encountered.\n",
    "\n",
    "Most of the time, we use one of two methods to deal with missing values.\n",
    "\n",
    "Method 1: drop all of the rows with a missing value\n",
    "We can use .dropna() to do this:\n",
    "\n",
    "bill_df = bill_df.dropna()\n",
    "This command will result in the DataFrame without the incomplete rows:\n",
    "\n",
    "day\tbill\ttip\tnum_guests\n",
    "“Mon”\t10.1\t1\t1\n",
    "“Mon”\t20.75\t5.5\t2\n",
    "“Wed”\t44.10\t15\t3\n",
    "\n",
    "|day|\tbill|\ttip|\tnum_guests|\n",
    "|---|---|---|---|\n",
    "|“Mon”\t|10.1|\t1|\t1|\n",
    "|“Mon”\t|20.75|\t5.5|\t2|\n",
    "|“Wed”\t|44.10|\t15\t|3|\n",
    "\n",
    "If we wanted to remove every row with a NaN value in the num_guests column only, we could specify a subset:\n",
    "\n",
    "bill_df = bill_df.dropna(subset=['num_guests'])\n",
    "Method 2: fill the missing values with the mean of the column, or with some other aggregate value.\n",
    "We can use .fillna() to do this:\n",
    "\n",
    "bill_df = bill_df.fillna(value={\"bill\":bill_df.bill.mean(), \"num_guests\":bill_df.num_guests.mean()})\n",
    "This command will result in the DataFrame with the respective mean of the column in the place of the original NaNs:\n",
    "\n",
    "day\tbill\ttip\tnum_guests\n",
    "“Mon”\t10.1\t1\t1\n",
    "“Mon”\t20.75\t5.5\t2\n",
    "“Tue”\t19.95\t5.5\t1.75\n",
    "“Wed”\t44.10\t15\t3\n",
    "“Wed”\t23.725\t1\t1\n",
    "\n",
    "|day|\tbill|\ttip|\tnum_guests|\n",
    "|---|---|---|---|\n",
    "|“Mon”\t|10.1|\t1|\t1|\n",
    "|“Mon”\t|20.75|\t5.5|\t2|\n",
    "|“Tue”\t|19.95|\t5.5\t|1.75|\n",
    "|“Wed”\t|44.10|\t15\t|3|\n",
    "|“Wed”\t|23.725\t|1\t|1|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "1.\n",
    "Get the mean of the score column. Store it in score_mean and print it out.\n",
    "\n",
    "Checkpoint 2 Passed\n",
    "2.\n",
    "We will assume that everyone who doesn’t have a score for an exam missed the test. We want to replace all nans with a score of 0. Let’s do this with the score column.\n",
    "\n",
    "Fill all of the nans in students['score'] with 0.\n",
    "\n",
    "Checkpoint 3 Passed\n",
    "\n",
    "Stuck? Get a hint\n",
    "3.\n",
    "Get the mean of the score column again. Store it in score_mean_2 and print it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77.69657422512235\n",
      "72.30971659919028\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "score_mean = students.score.mean()\n",
    "\n",
    "print(score_mean)\n",
    "\n",
    "students = students.fillna(0)\n",
    "\n",
    "score_mean_2 = students.score.mean()\n",
    "\n",
    "print(score_mean_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review\n",
    "Great! We have looked at a number of different methods we may use to get data into the format we want for analysis.\n",
    "\n",
    "Specifically, we have covered:\n",
    "\n",
    "* diagnosing the “tidiness” of the data\n",
    "* reshaping the data\n",
    "* combining multiple files\n",
    "* changing the types of values\n",
    "* dropping or filling missing values - how we deal with data that is incomplete or missing\n",
    "* manipulating strings to represent the data better\n",
    "\n",
    "You can use these methods to transform your datasets to be clean and easy to work with!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
